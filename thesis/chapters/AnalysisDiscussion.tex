\chapter{Analysis and Discussion}
\label{chap:AnalysisAndDiscussion}

The preceding chapters detailed the design and implementation of the \texttt{Arralac} compiler, culminating in a functional system capable of typechecking, evaluating, and providing interactive feedback for a lambda calculus with arbitrary-rank polymorphism. This chapter moves beyond description to provide a critical analysis of the project.

The analysis will proceed in three parts. First, I will analyze the core architectural contributions of this work, evaluating how the chosen design patterns successfully achieved the project's primary objectives and what trade-offs they entailed. Second, I will offer a qualitative evaluation of the system's non-functional characteristics, connecting them to the underlying design choices. Finally, I will critically examine the limitations of the current implementation and propose concrete directions for future research, framing the current work within a broader development context.

\section{Analyzing the Architectural Contributions}
\label{sec:Discussion:Objectives}

The primary goal of this thesis was to create a modern, tutorial-focused implementation of arbitrary-rank polymorphism, not merely by re-implementing existing algorithms, but by synthesizing foundational theory with modern compiler engineering practices. The success of this goal can be measured by analyzing the key architectural decisions that define \texttt{Arralac}.

\subsection{From Eager Unification to Constraint-Based Inference}
The most significant architectural contribution of this work is its adoption of a two-phase, constraint-based type inference model, a departure from the eager unification algorithm presented in \cite{jones-practical-2007}. In their paper, Peyton Jones et al. acknowledge the limitations of a simple left-to-right, eager algorithm for producing high-quality error messages and suggest that a "more principled alternative is to remove the arbitrary left-to-right order... get the inference algorithm to return a set of constraints, and solve them all together" \cite[Sec. 9.6]{jones-practical-2007}.

\texttt{Arralac} serves as a direct, working implementation of this very suggestion. By separating constraint generation (the \texttt{Typechecker}) from constraint solving (the \texttt{Solver}), this thesis demonstrates that the benefits of this architecture extend far beyond error reporting and are fundamental to building a modular and understandable system.

\paragraph{Architectural Benefits and Trade-offs}
This separation yielded two primary benefits:
\begin{enumerate}
    \item \textbf{Improved Modularity:} The logic of the typechecker and solver are cleanly decoupled. The \texttt{Typechecker}'s sole responsibility is to traverse the AST and emit a declarative set of \texttt{WantedConstraints}. It is entirely agnostic to the mechanics of unification. Conversely, the \texttt{Solver} operates on this abstract set of constraints, free from the complexities of AST traversal. This separation makes each component independently testable and significantly easier to reason about.
          % TODO typeof is not there.
    \item \textbf{A Foundation for Better Error Reporting:} A constraint-based model enables a holistic view of type errors. Consider a term like \texttt{f True 'a'} where \texttt{f} has the type \texttt{Int -> Char -> Bool}. An eager unifier might fail immediately upon seeing \texttt{True} and report a mismatch with \texttt{Int}, an error that is correct but potentially misleading. The \texttt{Arralac} pipeline, in contrast, gathers all constraints first: \texttt{(typeof True) ~ Int} and \texttt{(typeof 'a') ~ Char}. A future version of the solver could analyze this full set of conflicts to produce a much richer diagnostic, explaining that the call to \texttt{f} is incorrect in multiple ways.
\end{enumerate}

However, this design is not without costs. The primary trade-off is the added complexity of the \texttt{WantedConstraints} data structure itself. It becomes the sole, non-trivial interface between the two largest components of the inference engine. This required careful engineering to ensure that all necessary context---such as source locations for error reporting and skolem levels for scope checking---was correctly captured and propagated with each constraint, an overhead not present in a simpler eager system.

\subsection{The Trees That Grow AST: \\ A Necessity for Modern Tooling}
The second key architectural choice was the adoption of the \textbf{Trees That Grow} (TTG) pattern for the AST. While \cite{jones-practical-2007} used a simple, monolithic AST sufficient for their minimal language, the goals of this thesis---specifically the creation of an interactive language server---made such a design untenable.

The LSP requires the ability to annotate the AST with rich, pass-specific information, most notably the inferred type of every expression. The TTG pattern provides a type-safe and elegant solution to this problem. As demonstrated in \Cref{sec:Implementation:AST}, the AST is parameterized by the compiler pass, and type families are used to "grow" the tree with annotations like \texttt{TcAnno} only after the typechecking pass. This provides a compile-time guarantee that type information is not accessed before it has been computed, a crucial property for building a robust, multi-pass system and a clear improvement over ad-hoc solutions like \texttt{Maybe} fields. This choice directly addresses the research question of how to adapt modern compiler patterns for an educational setting.

\section{A Qualitative Evaluation of System Characteristics}
\label{sec:Discussion:Characteristics}
Beyond its core algorithms, the quality of a software artifact can be assessed against established principles, such as those outlined in the ISO 25010 standard for software quality. Evaluating \texttt{Arralac} against these principles reveals the practical impact of its design.

\begin{itemize}
    \item \textbf{Modularity:} The division of the codebase into 86 modules (\Cref{table:cloc}) is a direct and successful outcome of the pipeline architecture. The strict separation between stages like the \texttt{Renamer}, \texttt{Typechecker}, and \texttt{Solver} creates a highly modular system. This modularity makes the codebase highly \textbf{analysable}; a researcher or student interested only in constraint solving can study the \texttt{Solver} modules in isolation, with minimal cognitive overhead from the rest of the compiler.

    \item \textbf{Analysability (Error Handling):} In addition to modularity, the system's analysability is significantly enhanced by its error handling strategy. By defining distinct, descriptive error types for each pipeline stage, each capturing a full call stack, the system provides transparent and actionable diagnostics. During development, this allowed for rapid debugging, as the source of a failure (e.g., an unbound variable in the \texttt{Renamer} versus a failed unification in the \texttt{Solver}) was immediately apparent.

    \item \textbf{Installability and Portability:} The use of Nix for dependency management and installation is critical to the project's goal of being a usable and reproducible tutorial artifact. It guarantees that any user on a supported platform can build the executables and replicate the development environment with a single command. This addresses the common "it works on my machine" problem, making the research artifact genuinely accessible, verifiable, and portable.
\end{itemize}

\section{Limitations and Avenues for Future Work}
\label{sec:Discussion:Limitations}
A critical analysis requires acknowledging the project's limitations. The design of \texttt{Arralac} made deliberate simplifications to maintain its focus. These limitations, however, naturally suggest clear and valuable directions for future research.

\begin{enumerate}
    \item \textbf{Lack of \texttt{let}-generalization:} The most significant functional limitation is that the system does not perform ML-style generalization for local \texttt{let}-bindings, instead relying on user annotations for all polymorphism. While this simplifies the solver, it is a key feature of a practical functional language. The existing constraint-based architecture provides an excellent foundation for implementing this. Future work could add a scoped-solving phase at each \texttt{let}-binding, quantifying over any metavariables whose level is local to the binding's scope, as discussed in \cite{wits-type-inference-using-constraints}.

    \item \textbf{Untyped Core Language:} For pragmatic reasons, \texttt{Arralac} desugars its typed AST into a simple, untyped lambda calculus for evaluation. This forgoes the powerful, end-to-end consistency check that a typed intermediate language, like GHC's Core, provides. A major extension to this project would be to design and implement a typed Core language and extend the desugaring process to generate the necessary type abstractions and applications, thereby making the entire compilation pipeline type-safe.

    \item \textbf{Simplified Constraint Solver:} The current solver is functional but basic. It halts on the first unsolvable constraint and does not implement more advanced strategies, such as floating equality constraints out from under implication constraints to enable further solving. Enhancing the solver to handle these cases and to report a complete set of residual (unsolvable) constraints would be a valuable research project, leading to more powerful inference and even better error messages.
\end{enumerate}

In conclusion, the analysis confirms that \texttt{Arralac} is not merely a reimplementation, but a modernization and architectural evolution of the ideas presented in its foundational literature. It successfully serves its pedagogical purpose while also providing a robust, extensible foundation for future exploration into the art of compiler construction.